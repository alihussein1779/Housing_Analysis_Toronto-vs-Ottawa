{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "\n",
    "# For HTML parsing\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "\n",
    "# For website connections\n",
    "import requests \n",
    "\n",
    "# For data cleanup\n",
    "import re\n",
    "\n",
    "# For zipcode search\n",
    "#!pip install opencage\n",
    "from opencage.geocoder import OpenCageGeocode\n",
    "\n",
    "\n",
    "# To prevent overwhelming the server between connections\n",
    "import time\n",
    "from time import sleep \n",
    "\n",
    "# Display the progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# For creating plots\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.56s/it]\n"
     ]
    }
   ],
   "source": [
    "web_driver = webdriver.Chrome()\n",
    "\n",
    "# Function to collect raw data from url:\n",
    "\n",
    "def get_page(city, type, beds, page):\n",
    "  \n",
    "    url    = f'https://www.torontorentals.com/{city}/{type}?beds={beds}%20&p={page}'\n",
    "    result = requests.get(url)\n",
    "    # https://www.torontorentals.com/toronto/condos?beds=1%20&p=2\n",
    "    # check HTTP response status codes to find if HTTP request has been successfully completed\n",
    "    if result.status_code >= 100  and result.status_code <= 199:\n",
    "        print('Informational response')\n",
    "    if result.status_code >= 200  and result.status_code <= 299:\n",
    "        print('Successful response')\n",
    "        web_driver.get(url)\n",
    "        time.sleep(2)\n",
    "        web_driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        soup = BeautifulSoup(web_driver.page_source,'lxml')\n",
    "    if result.status_code >= 300  and result.status_code <= 399:\n",
    "        print('Redirect')\n",
    "    if result.status_code >= 400  and result.status_code <= 499:\n",
    "        print('Client error')\n",
    "    if result.status_code >= 500  and result.status_code <= 599:\n",
    "        print('Server error')\n",
    "        \n",
    "    return soup\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Data that will be used in the function\n",
    "house_type = [\"Apartment\",\"condo\",\"room\",\"house\",\"studio\",\"basement\"]\n",
    "bed_options = [\"0\",\"1\",\"2\",\"3\",\"4\",\"1-2\",\"1-3\"]\n",
    "\n",
    "# Lists that will contain the clean data\n",
    "listData = []\n",
    "listingStreet = []\n",
    "listingCity = []\n",
    "listingZip = []\n",
    "listingRent = []\n",
    "listingBed = []\n",
    "listingBath = []\n",
    "listingDim = []\n",
    "listingType = []\n",
    "ListingLink = []\n",
    "ListingID = []\n",
    "\n",
    "# Code that implements the above function and the above lists to collect raw data          \n",
    "  \n",
    "for page_num in tqdm(range(1,2)):  # Range depends on how many pages you want to analyze\n",
    "    soup_page                = get_page('ottawa', house_type, bed_options, page_num)\n",
    "            \n",
    "  \n",
    "  #Data Collection\n",
    "     \n",
    "    #This contains info on all datapoints needed, but will use other links instead to avoid mistakes during the clean up process\n",
    "    data = soup_page.find_all(\"div\",{\"class\":\"r-listing-card-v\"})\n",
    "    listData.append(data)  \n",
    "    \n",
    "    \n",
    "    # Street, Rent & House type had unique identifiers in the HTML \n",
    "    street                   = soup_page.find_all(\"div\",{\"class\":\"r-listing-address q-mb-md q-pl-md\"})\n",
    "    rent                     = soup_page.find_all(\"a\",{\"class\":\"r-listing-price q-my-md q-mr-md q-pl-md\"})\n",
    "    house_type               = soup_page.find_all(\"span\",{\"class\":\"r-listing-type\"})\n",
    "\n",
    "    # Bed, Bath and Dimensions had the same identifier from the HTML\n",
    "    data_bed_bath_dimensions = soup_page.find_all(\"span\",{\"class\":\"r-listing-infos__label\"})\n",
    "   \n",
    "\n",
    "    # Data Cleanup # Appending to Lists\n",
    "    \n",
    "    # Street & House type had unique identifiers in the HTML \n",
    "\n",
    "    # Address\n",
    "    str_street              = [str(item) for item in street]\n",
    "    cleaned_street          = [sub.replace('<div class=\"r-listing-address q-mb-md q-pl-md\">',\"\")\n",
    "                               .replace('</div>',\"\") for sub in str_street]\n",
    "    for i in cleaned_street:\n",
    "        listingStreet.append(i)\n",
    "        \n",
    "    # House Type    \n",
    "    str_house_type          = [str(item) for item in house_type]\n",
    "    cleaned_house_type      = [sub.replace('<span class=\"r-listing-type\">',\"</span>,\")\n",
    "                               .replace('</span>',\"\").replace(\",\",\"\") for sub in str_house_type]\n",
    "    for i in cleaned_house_type:\n",
    "        listingType.append(i)    \n",
    "        \n",
    "        \n",
    "    # Price    \n",
    "    str_rent                = [str(item) for item in rent]\n",
    "    rent_1                  = [sub.replace('<a class=\"r-listing-price q-my-md q-mr-md q-pl-md\"','').replace('href=\"/toronto/','')\n",
    "                                .replace('</a>',\"\").replace(\",\",\"\") for sub in str_rent]\n",
    "    rent_2                  = [item.split(\">\") for item in rent_1]\n",
    "    cleaned_rent            = [' - '.join(item.split(' - ')[:2]) for _, item in rent_2]\n",
    "    for i in cleaned_rent:\n",
    "        listingRent.append(i)\n",
    "        \n",
    "    # Bed, Bath & Dimensions    \n",
    "    str_data_bed_bath_dimensions    = [str(item) for item in data_bed_bath_dimensions]\n",
    "    cleaned_dimensions_bath_bed     = [sub.replace('<span data-current-language=\"en-US\"',\"\")\n",
    "                                      .replace('<span class=\"r-listing-infos__label\">',\"\")\n",
    "                                      .replace('data-msgid=',\"\").replace('>bed</span></span>',\"\")\n",
    "                                      .replace('>bath</span></span>',\"\").replace('>Ft</span></span>',\"\")\n",
    "                                       for sub in str_data_bed_bath_dimensions]\n",
    "\n",
    "    combined_info = []\n",
    "    listingCombinedInfo = []\n",
    "    for i in range(0, len(cleaned_dimensions_bath_bed), 3):\n",
    "        bed                 = cleaned_dimensions_bath_bed[i].split()[0] if i < len(cleaned_dimensions_bath_bed) else \"N/A\"\n",
    "        bath                = cleaned_dimensions_bath_bed[i + 1].split()[0] if i + 1 < len(cleaned_dimensions_bath_bed) else \"N/A\"\n",
    "        sqft                = cleaned_dimensions_bath_bed[i + 2].split()[0] if i + 2 < len(cleaned_dimensions_bath_bed) else \"N/A\"\n",
    "\n",
    "        combined_info.append(f\"{bed} bed, {bath} bath, {sqft} ft\")\n",
    "        listingCombinedInfo.append(combined_info)\n",
    "\n",
    "    # Now combined_info contains the desired combined strings with the specified order and \"N/A\" for missing values.\n",
    "\n",
    "    for item in combined_info:\n",
    "        parts               = item.split(', ')\n",
    "        \n",
    "        bed_part            = parts[0].split()[0]\n",
    "        listingBed.append(bed_part)\n",
    "        \n",
    "        bath_part           = parts[1].split()[0]\n",
    "        listingBath.append(bath_part)\n",
    "        \n",
    "        dim_part            = parts[2].split()[0]\n",
    "        listingDim.append(dim_part)  \n",
    "        \n",
    "        \n",
    "   \n",
    "    # For IDs:\n",
    "    \n",
    "    # Find all <a> elements with the class \"r-listing-price\"\n",
    "    anchor_elements = soup_page.find_all('a', class_='r-listing-price')\n",
    "\n",
    "    # Iterate through the <a> elements and extract the IDs\n",
    "    for anchor_element in anchor_elements:\n",
    "        href = anchor_element['href']\n",
    "\n",
    "        # Extract the ID from the href attribute using regular expressions\n",
    "        id_match = re.search(r'id(\\d+)', href)\n",
    "        if id_match:\n",
    "            listing_id = id_match.group(1)\n",
    "            ListingID.append(listing_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To obtain the zipcodes for addresses\n",
    "\n",
    "# Initialize the OpenCageGeocode API key\n",
    "api_key = \"4d9d18c5a56040578558ee2d57caaf6f\"  #personal API key\n",
    "\n",
    "# Initialize the geocoder\n",
    "geocoder = OpenCageGeocode(api_key)\n",
    "\n",
    "\n",
    "# Function to extract city and postal code from address\n",
    "def extract_city_and_zip(address):\n",
    "    parts = address.split('-')\n",
    "    if len(parts) > 1:\n",
    "        city_part = parts[1].strip()  # Get the part after the hyphen and remove leading/trailing spaces\n",
    "        city = city_part.split(',')[0].strip()  # Extract the city name before the comma and remove spaces\n",
    "        return city\n",
    "    return None\n",
    "\n",
    "# Search for the postal code for each address in the list and add to the list of dictionaries\n",
    "for address in listingStreet:\n",
    "    result = geocoder.geocode(address, countrycode=\"CA\")\n",
    "    if result and 'components' in result[0]:\n",
    "        components = result[0]['components']\n",
    "        postal_code = components.get('postcode', 'Postal code not found')\n",
    "        listingZip.append(postal_code)\n",
    "    else:\n",
    "        listingZip.append('Postal code not found')\n",
    "\n",
    "# Function to extract city and postal code from address\n",
    "def extract_city_and_zip(address):\n",
    "    parts = address.split('-')\n",
    "    if len(parts) > 1:\n",
    "        right_part = parts[1].strip()  # Get the part after the hyphen and remove leading/trailing spaces\n",
    "        city_and_province = right_part.split(',')  # Split by comma to separate city and province\n",
    "        if len(city_and_province) > 1:\n",
    "            city = city_and_province[0].strip()  # Extract the city name and remove spaces\n",
    "            return city\n",
    "    return None\n",
    "\n",
    "# Apply the function to each element in the ListingStreet list\n",
    "for address in listingStreet:\n",
    "    city = extract_city_and_zip(address)\n",
    "    if city:\n",
    "        listingCity.append(city)\n",
    "    else:\n",
    "        listingCity.append('City not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "0\n",
      "10\n",
      "9\n",
      "10\n",
      "['708878', '408746', '518420', '580823', '561296', '392871', '612300', '344041', '255883', '582285']\n"
     ]
    }
   ],
   "source": [
    "print(len(listingCity))\n",
    "print(len(listingType))\n",
    "print(len(listingBed))\n",
    "print(len(listingBath))\n",
    "print(len(listingDim))\n",
    "print(len(listingStreet))\n",
    "print(len(listingZip))\n",
    "print(len(listingRent))\n",
    "print(len(listingCombinedInfo))\n",
    "print(len(ListingID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Bed Bath and SQ Ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'708878': '1-2', '408746': '0-1', '518420': '1', '580823': '1', '561296': '1', '392871': '2', '612300': '1-2', '344041': '1-2', '255883': '2', '582285': None}\n",
      "{'708878': '2', '408746': '1', '518420': '756', '580823': '167', '561296': '470', '392871': '1-2.5', '612300': '2', '344041': '2', '255883': '954', '582285': None}\n",
      "{'708878': '856', '408746': '0-1', '518420': '1', '580823': '0-2', '561296': '1-2', '392871': '1', '612300': '1179', '344041': '1-2', '255883': 'N/A', '582285': None}\n",
      "{'708878': {'bedroom': '1-2', 'bathroom': '2', 'sqft': '856'}, '408746': {'bedroom': '0-1', 'bathroom': '1', 'sqft': '0-1'}, '518420': {'bedroom': '1', 'bathroom': '756', 'sqft': '1'}, '580823': {'bedroom': '1', 'bathroom': '167', 'sqft': '0-2'}, '561296': {'bedroom': '1', 'bathroom': '470', 'sqft': '1-2'}, '392871': {'bedroom': '2', 'bathroom': '1-2.5', 'sqft': '1'}, '612300': {'bedroom': '1-2', 'bathroom': '2', 'sqft': '1179'}, '344041': {'bedroom': '1-2', 'bathroom': '2', 'sqft': '1-2'}, '255883': {'bedroom': '2', 'bathroom': '954', 'sqft': 'N/A'}, '582285': {'bedroom': None, 'bathroom': None, 'sqft': None}}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with the data, using None for missing values\n",
    "data = {\n",
    "    \"id\": ListingID,\n",
    "    \"bedroom\": listingBed + [None] * (len(ListingID) - len(listingBed)),\n",
    "    \"bathroom\": listingBath + [None] * (len(ListingID) - len(listingBath)),\n",
    "    \"sq ft\": listingDim + [None] * (len(ListingID) - len(listingDim))\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_incorrect = pd.DataFrame(data)\n",
    "\n",
    "# Create dictionaries with the IDs and the data from bed, bath and sq ft\n",
    "\n",
    "# Initialize empty dictionaries\n",
    "bedroom_dict = {}\n",
    "bathroom_dict = {}\n",
    "sqft_dict = {}\n",
    "\n",
    "# Iterate through the DataFrame rows and populate the dictionaries\n",
    "for index, row in df_incorrect.iterrows():\n",
    "    listing_id = row[\"id\"]\n",
    "    \n",
    "    # Create dictionaries with ID and respective values\n",
    "    bedroom_dict[listing_id] = row[\"bedroom\"]\n",
    "    bathroom_dict[listing_id] = row[\"bathroom\"]\n",
    "    sqft_dict[listing_id] = row[\"sq ft\"]\n",
    "    \n",
    "\n",
    "# Clean-up\n",
    "print(bedroom_dict)\n",
    "print(bathroom_dict)\n",
    "print(sqft_dict)\n",
    "\n",
    "# Sample dictionaries\n",
    "bedroom_dict = {'708878': '1-2', '408746': '0-1', '518420': '1', '580823': '1', '561296': '1', '392871': '2', '612300': '1-2', '344041': '1-2', '255883': '2', '582285': None}\n",
    "bathroom_dict = {'708878': '2', '408746': '1', '518420': '756', '580823': '167', '561296': '470', '392871': '1-2.5', '612300': '2', '344041': '2', '255883': '954', '582285': None}\n",
    "sqft_dict = {'708878': '856', '408746': '0-1', '518420': '1', '580823': '0-2', '561296': '1-2', '392871': '1', '612300': '1179', '344041': '1-2', '255883': 'N/A', '582285': None}\n",
    "\n",
    "# Initialize a combined dictionary\n",
    "combined_dict = {}\n",
    "\n",
    "# Iterate through keys in the dictionaries and combine them\n",
    "for key in bedroom_dict.keys():\n",
    "    combined_dict[key] = {\n",
    "        'bedroom': bedroom_dict.get(key),\n",
    "        'bathroom': bathroom_dict.get(key),\n",
    "        'sqft': sqft_dict.get(key)\n",
    "    }\n",
    "\n",
    "# Print the combined dictionary\n",
    "print(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'708878': {'bedroom': None, 'bathroom': None, 'sqft': None}, '408746': {'bedroom': None, 'bathroom': None, 'sqft': None}, '518420': {'bedroom': None, 'bathroom': None, 'sqft': None}, '580823': {'bedroom': None, 'bathroom': None, 'sqft': None}, '561296': {'bedroom': None, 'bathroom': None, 'sqft': None}, '392871': {'bedroom': None, 'bathroom': None, 'sqft': None}, '612300': {'bedroom': None, 'bathroom': None, 'sqft': None}, '344041': {'bedroom': None, 'bathroom': None, 'sqft': None}, '255883': {'bedroom': None, 'bathroom': None, 'sqft': None}, '582285': {'bedroom': None, 'bathroom': None, 'sqft': None}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a combined dictionary\n",
    "combined_dict = {}\n",
    "\n",
    "# Helper function to move values between keys\n",
    "def move_value(source_dict, dest_dict, key, field_name):\n",
    "    if key in source_dict and source_dict[key] is not None:\n",
    "        dest_dict[key][field_name] = source_dict[key]\n",
    "        source_dict[key] = None\n",
    "\n",
    "# Process each key and correct errors\n",
    "for key in bedroom_dict.keys():\n",
    "    combined_dict[key] = {'bedroom': None, 'bathroom': None, 'sqft': None}\n",
    "\n",
    "    # Correct errors based on conditions\n",
    "    if bedroom_dict[key] and '-' in bedroom_dict[key]:\n",
    "        combined_dict[key]['bedroom'] = bedroom_dict[key]\n",
    "        bedroom_dict[key] = None\n",
    "    if bathroom_dict[key] and '-' in bathroom_dict[key]:\n",
    "        combined_dict[key]['bedroom'] = bathroom_dict[key]\n",
    "        bathroom_dict[key] = None\n",
    "    if sqft_dict[key] and '-' in sqft_dict[key]:\n",
    "        combined_dict[key]['bedroom'] = sqft_dict[key]\n",
    "        sqft_dict[key] = None\n",
    "\n",
    "    # Move values to the correct keys\n",
    "    move_value(bedroom_dict, combined_dict, key, 'bedroom')\n",
    "    move_value(bathroom_dict, combined_dict, key, 'bathroom')\n",
    "    move_value(sqft_dict, combined_dict, key, 'sqft')\n",
    "\n",
    "# Print the corrected combined dictionary\n",
    "print(combined_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Dataframe and Consolidating Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Property Type Bedrooms Bathrooms Square Footage                                    Address Zip code          Price\n",
      "City                                                                                                                             \n",
      "Ottawa             apartment      1-2         2            856                90 Champagne  - Ottawa , ON  K1S 4P1  $2100 - $2900\n",
      "City not found     apartment      0-1         1            0-1       253 - 257 York Street  - Ottawa , ON  K1N 5T9  $1675 - $1850\n",
      "City not found     apartment        1       756              1                86-92 Hinton  - Ottawa , ON  K1Y 2Z7  $1700 - $2200\n",
      "City not found     apartment        1       167            0-2      150-152 Osgoode Street  - Ottawa , ON  K1N 8A4          $1400\n",
      "Ottawa             apartment        1       470            1-2                  256 Rideau  - Ottawa , ON  K1N 0A9  $1375 - $2500\n",
      "...                      ...      ...       ...            ...                                        ...      ...            ...\n",
      "Ottawa                studio     None      None           None       185 Lyon Street North  - Ottawa , ON  K1R 7X6          $1669\n",
      "Ottawa          private-room     None      None           None  101 Champagne Avenue South  - Ottawa , ON  K1S 4P1          $1150\n",
      "Nepean          private-room     None      None           None  1435 Prince of Wales Drive  - Nepean , ON  K2G 7B3           $710\n",
      "Nepean                 house     None      None           None           53 Overlake Drive  - Nepean , ON  K2E 7X5          $2500\n",
      "Ottawa           shared-room     None      None           None         83 Sweetland Avenue  - Ottawa , ON  K1N 6V9           $700\n",
      "\n",
      "[805 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  # Import numpy for NaN values\n",
    "\n",
    "# Find the maximum length among all lists\n",
    "max_length = max(len(listingCity), len(listingType), len(listingBed), len(listingBath),\n",
    "                 len(listingDim), len(listingStreet), len(listingZip), len(listingRent))\n",
    "\n",
    "# Pad the shorter lists with None or NaN to match the maximum length\n",
    "def pad_list(lst, length, pad_value=None):\n",
    "    if len(lst) < length:\n",
    "        return lst + [pad_value] * (length - len(lst))\n",
    "    else:\n",
    "        return lst\n",
    "\n",
    "listingCity = pad_list(listingCity, max_length)\n",
    "listingType = pad_list(listingType, max_length)\n",
    "listingBed = pad_list(listingBed, max_length)\n",
    "listingBath = pad_list(listingBath, max_length)\n",
    "listingDim = pad_list(listingDim, max_length)\n",
    "listingStreet = pad_list(listingStreet, max_length)\n",
    "listingZip = pad_list(listingZip, max_length)\n",
    "listingRent = pad_list(listingRent, max_length)\n",
    "\n",
    "# Create the DataFrame\n",
    "column_names = [\"City\", \"Property Type\", \"Bedrooms\", \"Bathrooms\", \"Square Footage\", \"Address\",\n",
    "                \"Zip code\", \"Price\"]\n",
    "data = {\n",
    "    \"City\": listingCity,\n",
    "    \"Property Type\": listingType,\n",
    "    \"Bedrooms\": listingBed,\n",
    "    \"Bathrooms\": listingBath,\n",
    "    \"Square Footage\": listingDim,\n",
    "    \"Address\": listingStreet,\n",
    "    \"Zip code\": listingZip,\n",
    "    \"Price\": listingRent\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set the index (if needed)\n",
    "df.set_index('City', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.shape[0]\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"D:\\Projects\\Rentals/\"\n",
    "df.to_excel(\"rental_data_ottawa_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nReferences:\\n1. Web Scraping Rentals Website Using Python Beautiful Soup: https://medium.com/swlh/web-scraping-rentals-website-using-beautiful-soup-and-pandas-99e255f27052\\n2. Chat GPT (For fine-tuning)\\n3. StackOverflow\\n4. Google\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "References:\n",
    "1. Web Scraping Rentals Website Using Python Beautiful Soup: https://medium.com/swlh/web-scraping-rentals-website-using-beautiful-soup-and-pandas-99e255f27052\n",
    "2. Chat GPT (For fine-tuning)\n",
    "3. StackOverflow\n",
    "4. Google\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
